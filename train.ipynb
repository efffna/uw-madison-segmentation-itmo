{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q ../input/pytorch-segmentation-models-lib/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\n",
    "#!pip install -q ../input/pytorch-segmentation-models-lib/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\n",
    "#!pip install -q ../input/pytorch-segmentation-models-lib/timm-0.4.12-py3-none-any.whl\n",
    "#!pip install -q ../input/pytorch-segmentation-models-lib/segmentation_models_pytorch-0.2.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil # shutil not used\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold # only StratifiedGroupKFold used\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.cuda import amp\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('experiments', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"experiments/exp{}/\".format(\n",
    "        str(len([i for i in os.listdir(\"experiments/\") if i.startswith(\"exp\")]) + 1)\n",
    "    )\n",
    "os.makedirs(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 101\n",
    "    debug = False \n",
    "    exp_name = 'Baseline'\n",
    "    comment = 'timm-mobilenetv3_large_100-224x224'\n",
    "    model_name = 'UnetPlusPlus'\n",
    "    backbone = 'timm-mobilenetv3_large_100'\n",
    "    project_name = \"uw-segmentation\"\n",
    "    team_name = \"cv-itmo\"\n",
    "    train_bs = 32\n",
    "    valid_bs = train_bs\n",
    "    img_size = [224, 224]\n",
    "    epochs = 10\n",
    "    lr = 2e-3\n",
    "    scheduler = 'ReduceLROnPlateau'\n",
    "    min_lr = 1e-6\n",
    "    T_max = int(30000/train_bs*epochs)+50\n",
    "    T_0 = 25\n",
    "    warmup_epochs = 0\n",
    "    wd = 1e-6\n",
    "    n_accumulate = max(1, 32//train_bs)\n",
    "    n_fold = 5\n",
    "    num_classes = 3\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    thr = 0.45\n",
    "    log_path = log_path\n",
    "    wandb_logging = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments/exp1/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcv-itmo\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.19 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/uw/seg/data/wandb/run-20220629_012624-1e6ajxwm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cv-itmo/uw-segmentation/runs/1e6ajxwm\" target=\"_blank\">timm-mobilenetv3_large_100-224x224</a></strong> to <a href=\"https://wandb.ai/cv-itmo/uw-segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG.wandb_logging:\n",
    "    wandb.init(\n",
    "            project=CFG.project_name,\n",
    "            name=CFG.comment,\n",
    "            entity=CFG.team_name,\n",
    "            config={\n",
    "                \"server\": 'own server',\n",
    "                \"experiments\": CFG.log_path,\n",
    "                \"epochs\": CFG.epochs,\n",
    "                \"batch_size\": CFG.train_bs,\n",
    "                \"model name\": CFG.model_name,\n",
    "                \"encoder name\": CFG.backbone,\n",
    "                \"loss\": 'SoftBCE',\n",
    "                \"fold number\": 0\n",
    "            },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2mask(id_, df=None):\n",
    "    idf = df[df['id']==id_]\n",
    "    wh = idf[['height','width']].iloc[0]\n",
    "    shape = (wh.height, wh.width, 3)\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n",
    "        cdf = idf[idf['class']==class_]\n",
    "        rle = cdf.segmentation.squeeze()\n",
    "        if len(cdf) and not pd.isna(rle):\n",
    "            mask[..., i] = rle_decode(rle, shape[:2])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    data = row['id'].split('_')\n",
    "    case = int(data[0].replace('case',''))\n",
    "    day = int(data[1].replace('day',''))\n",
    "    slice_ = int(data[-1])\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    return row\n",
    "\n",
    "def path2info(row):\n",
    "    path = row['image_path']\n",
    "    data = path.split('/')\n",
    "    slice_ = int(data[-1].split('_')[1])\n",
    "    case = int(data[-3].split('_')[0].replace('case',''))\n",
    "    day = int(data[-3].split('_')[1].replace('day',''))\n",
    "    width = int(data[-1].split('_')[2])\n",
    "    height = int(data[-1].split('_')[3])\n",
    "    row['height'] = height\n",
    "    row['width'] = width\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if len(img.shape)==2:\n",
    "        img = np.tile(img[...,None], [1, 1, 3])\n",
    "    img = img.astype('float32') \n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx \n",
    "    return img\n",
    "\n",
    "def load_msk(path):\n",
    "    msk = None\n",
    "    if path.split('.')[-1] in ['jpg','png', 'jpeg']:\n",
    "        msk = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    elif path.split('.')[-1] == 'npy':\n",
    "        msk = np.load(path)\n",
    "    else:\n",
    "        pass\n",
    "    msk = msk.astype('float32')\n",
    "    msk/=255.0    \n",
    "    return msk\n",
    "\n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    if mask is not None:\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "\n",
    "def rle_encode(img):\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/train.csv')\n",
    "#df = df.progress_apply(get_metadata, axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths = glob('data/train/*/*/*/*')\n",
    "#path_df = pd.DataFrame(paths, columns=['image_path'])\n",
    "#path_df = path_df.progress_apply(path2info, axis=1)\n",
    "#df = df.merge(path_df, on=['case','day','slice'])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(id_,df=None, count=0):\n",
    "    idf = df[df['id']==id_]\n",
    "    mask = id2mask(id_, df=df) # mask from [0, 1] to [0, 255]\n",
    "    image_path = idf.image_path.iloc[0]\n",
    "    img = load_img(image_path) # load image\n",
    "    mask_path = image_path.replace('data/train/','data/tmp/png/')\n",
    "    mask_folder = mask_path.rsplit('/',1)[0]\n",
    "    os.makedirs(mask_folder, exist_ok=True)\n",
    "    cv2.imwrite(mask_path, mask*255, [cv2.IMWRITE_PNG_COMPRESSION, 1]) # write mask as .png\n",
    "    mask_path2 = image_path.replace('data/train/','data/tmp/np/').replace('.png','.npy')\n",
    "    mask_folder2 = mask_path2.rsplit('/',1)[0]\n",
    "    os.makedirs(mask_folder2, exist_ok=True)\n",
    "    np.save(mask_path2, mask*255) \n",
    "\n",
    "    return mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_df = df.copy()\n",
    "#ids = tmp_df['id'].unique()\n",
    "#_ = Parallel(n_jobs=-1, backend='threading')(delayed(save_mask)(id_, df=tmp_df, count=i)\\\n",
    "#                                             for i, id_ in enumerate(tqdm(ids, total=len(ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['mask_path'] = df.image_path.str.replace('data/train','data/tmp/png')\n",
    "#df.to_csv('train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>/kaggle/input/uwmgi-mask-dataset/png//uw-madis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>/kaggle/input/uwmgi-mask-dataset/png//uw-madis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>/kaggle/input/uwmgi-mask-dataset/png//uw-madis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id        class segmentation  case  day  slice  \\\n",
       "0  case123_day20_slice_0001  large_bowel          NaN   123   20      1   \n",
       "1  case123_day20_slice_0001  small_bowel          NaN   123   20      1   \n",
       "2  case123_day20_slice_0001      stomach          NaN   123   20      1   \n",
       "\n",
       "                                          image_path  height  width  \\\n",
       "0  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266   \n",
       "1  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266   \n",
       "2  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266   \n",
       "\n",
       "                                           mask_path  \n",
       "0  /kaggle/input/uwmgi-mask-dataset/png//uw-madis...  \n",
       "1  /kaggle/input/uwmgi-mask-dataset/png//uw-madis...  \n",
       "2  /kaggle/input/uwmgi-mask-dataset/png//uw-madis...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./uwmgi-mask-dataset/train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10615</th>\n",
       "      <td>case44_day0_slice_0083</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>26975 2 27239 6 27504 8 27769 9 28034 10 28299...</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>./uw-madison-gi-tract-image-segmentation/train...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id        class  \\\n",
       "10615  case44_day0_slice_0083  small_bowel   \n",
       "\n",
       "                                            segmentation  case  day  slice  \\\n",
       "10615  26975 2 27239 6 27504 8 27769 9 28034 10 28299...    44    0     83   \n",
       "\n",
       "                                              image_path  height  width  \\\n",
       "10615  ./uw-madison-gi-tract-image-segmentation/train...     266    266   \n",
       "\n",
       "                                               mask_path  \n",
       "10615  ./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_path'] = df.image_path.str.replace('/kaggle/input','.')\n",
    "df['mask_path'] = df.mask_path.str.replace('/kaggle/input','.')\n",
    "df['mask_path'] = df.mask_path.str.replace('//','/')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>rle_len</th>\n",
       "      <th>empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>./uw-madison-gi-tract-image-segmentation/train...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>./uw-madison-gi-tract-image-segmentation/train...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0003</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>./uw-madison-gi-tract-image-segmentation/train...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0004</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>./uw-madison-gi-tract-image-segmentation/train...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0005</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>./uw-madison-gi-tract-image-segmentation/train...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  case  day  slice  \\\n",
       "0  case123_day20_slice_0001   123   20      1   \n",
       "1  case123_day20_slice_0002   123   20      2   \n",
       "2  case123_day20_slice_0003   123   20      3   \n",
       "3  case123_day20_slice_0004   123   20      4   \n",
       "4  case123_day20_slice_0005   123   20      5   \n",
       "\n",
       "                                          image_path  height  width  \\\n",
       "0  ./uw-madison-gi-tract-image-segmentation/train...     266    266   \n",
       "1  ./uw-madison-gi-tract-image-segmentation/train...     266    266   \n",
       "2  ./uw-madison-gi-tract-image-segmentation/train...     266    266   \n",
       "3  ./uw-madison-gi-tract-image-segmentation/train...     266    266   \n",
       "4  ./uw-madison-gi-tract-image-segmentation/train...     266    266   \n",
       "\n",
       "                                           mask_path segmentation  rle_len  \\\n",
       "0  ./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...       [, , ]        0   \n",
       "1  ./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...       [, , ]        0   \n",
       "2  ./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...       [, , ]        0   \n",
       "3  ./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...       [, , ]        0   \n",
       "4  ./uwmgi-mask-dataset/png/uw-madison-gi-tract-i...       [, , ]        0   \n",
       "\n",
       "   empty  \n",
       "0   True  \n",
       "1   True  \n",
       "2   True  \n",
       "3   True  \n",
       "4   True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['segmentation'] = df.segmentation.fillna('')\n",
    "df['rle_len'] = df.segmentation.map(len) \n",
    "#df['mask_path'] = df.mask_path.str.replace('/np/','/png/')#.str.replace('.npy','.png')\n",
    "\n",
    "df2 = df.groupby(['id'])['segmentation'].agg(list).to_frame().reset_index() # rle list of each id\n",
    "df2 = df2.merge(df.groupby(['id'])['rle_len'].agg(sum).to_frame().reset_index()) # total length of all rles of each id\n",
    "\n",
    "df = df.drop(columns=['segmentation', 'class', 'rle_len'])\n",
    "df = df.groupby(['id']).head(1).reset_index(drop=True)\n",
    "df = df.merge(df2, on=['id'])\n",
    "df['empty'] = (df.rle_len==0) # empty masks\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['empty'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold  empty\n",
       "0.0   False    3257\n",
       "      True     4551\n",
       "1.0   False    3540\n",
       "      True     4540\n",
       "2.0   False    3053\n",
       "      True     3923\n",
       "3.0   False    3407\n",
       "      True     4801\n",
       "4.0   False    3333\n",
       "      True     4091\n",
       "Name: id, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['empty'], groups = df[\"case\"])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "display(df.groupby(['fold','empty'])['id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "        self.img_paths = df['image_path'].tolist()\n",
    "        self.ids = df['id'].tolist()\n",
    "        if 'mask_path' in df.columns:\n",
    "            self.msk_paths  = df['mask_path'].tolist()\n",
    "        else:\n",
    "            self.msk_paths = None\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        id_ = self.ids[index]\n",
    "        img = []\n",
    "        img = load_img(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "        if self.label:\n",
    "            msk_path = self.msk_paths[index]\n",
    "            msk = load_msk(msk_path)\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img  = data['image']\n",
    "                msk  = data['mask']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            msk = np.transpose(msk, (2, 0, 1))\n",
    "            return torch.tensor(img), torch.tensor(msk)\n",
    "        else:\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.tensor(img), id_, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "        ], p=0.25),\n",
    "        A.CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
    "                         min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ], p=1.0),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        ], p=1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(df, fold, debug=False):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    if debug:\n",
    "        train_df = train_df.head(32*5).query(\"empty==0\")\n",
    "        valid_df = valid_df.head(32*3).query(\"empty==0\")\n",
    "    train_dataset = BuildDataset(train_df, transforms=data_transforms['train'])\n",
    "    valid_dataset = BuildDataset(valid_df, transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs if not debug else 20, \n",
    "                             shuffle=True, drop_last=False) #  num_workers=4, \n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs if not debug else 20, \n",
    "                               shuffle=False) # num_workers=4,\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=CFG.backbone,     \n",
    "        encoder_weights=\"imagenet\",     \n",
    "        in_channels=3,                  \n",
    "        classes=CFG.num_classes,        \n",
    "        activation=None,\n",
    "    )\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "JaccardLoss = smp.losses.JaccardLoss(mode='multilabel')\n",
    "DiceLoss = smp.losses.DiceLoss(mode='multilabel')\n",
    "BCELoss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss = smp.losses.LovaszLoss(mode='multilabel', per_image=False)\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False)\n",
    "IoU_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return BCELoss(y_pred, y_true)# + 0.5*TverskyLoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    tr_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            y_pred = model(images)\n",
    "            loss = criterion(y_pred, masks)\n",
    "            loss = loss / CFG.n_accumulate\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "    \n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        y_pred = nn.Sigmoid()(y_pred)\n",
    "        #val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        tr_jaccard = IoU_metric(masks, y_pred).cpu().detach().numpy()\n",
    "        tr_scores.append(tr_jaccard)\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, np.mean(tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:        \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, masks)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        y_pred = nn.Sigmoid()(y_pred)\n",
    "        val_dice = DiceLoss(masks, y_pred).cpu().detach().numpy()\n",
    "        val_jaccard = IoU_metric(masks, y_pred).cpu().detach().numpy()\n",
    "        val_scores.append([val_dice, val_jaccard])\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    val_scores = np.mean(val_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):   \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss  = np.inf\n",
    "    best_epoch = -1\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss, train_score = train_one_epoch(model, optimizer, #scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "        \n",
    "        val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                 device=CFG.device, \n",
    "                                                 epoch=epoch)\n",
    "        val_dice, val_jaccard = val_scores\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "    \n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Train IoU'].append(train_score)\n",
    "\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Dice'].append(val_dice)\n",
    "        history['Valid IoU'].append(val_jaccard)\n",
    "        \n",
    "        print(\"Logging Wandb.\")\n",
    "        wandb.log(\n",
    "                    {\n",
    "                        f\"train/Loss\": np.float64(train_loss),\n",
    "                        f\"train/IoU\": np.float64(train_score),\n",
    "                        f\"val/Loss\": np.float64(val_loss),\n",
    "                        f\"val/Dice\": np.float64(val_dice),\n",
    "                        f\"val/IoU\": np.float64(val_jaccard),\n",
    "                    }\n",
    "                    )\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            print(f\"{c_}Valid Score Improved ({best_loss:0.4f} ---> {val_loss:0.4f})\")\n",
    "            best_loss = val_loss\n",
    "            best_jaccard = val_jaccard\n",
    "            best_epoch = epoch\n",
    "\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"{CFG.log_path}best_model_f{fold}_ep{best_epoch}.pt\"\n",
    "            torch.save(model.state_dict(), PATH)      \n",
    "\n",
    "            \n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"{CFG.log_path}last_epoch_f{fold}.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "            \n",
    "        print(); print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Score: {:.4f}\".format(best_jaccard))\n",
    "    wandb.summary[\"Best Score IoU\"] = np.float64(best_jaccard)\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, \n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: GeForce GTX 1080 Ti\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [20:24<00:00,  1.28s/it, gpu_mem=3.11 GB, lr=0.00200, train_loss=0.0205]  \n",
      "Valid : 100%|██████████| 244/244 [01:31<00:00,  2.67it/s, gpu_memory=1.50 GB, lr=0.00200, valid_loss=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9846 | Valid Jaccard: 0.2118\n",
      "\u001b[32mValid Score Improved (inf ---> 0.0137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 2/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [20:21<00:00,  1.27s/it, gpu_mem=3.25 GB, lr=0.00200, train_loss=0.0087]  \n",
      "Valid : 100%|██████████| 244/244 [01:32<00:00,  2.65it/s, gpu_memory=1.61 GB, lr=0.00200, valid_loss=0.0085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9867 | Valid Jaccard: 0.2585\n",
      "\u001b[32mValid Score Improved (0.0137 ---> 0.0085)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 3/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [21:01<00:00,  1.32s/it, gpu_mem=3.25 GB, lr=0.00200, train_loss=0.0079]  \n",
      "Valid : 100%|██████████| 244/244 [01:25<00:00,  2.84it/s, gpu_memory=1.50 GB, lr=0.00200, valid_loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9855 | Valid Jaccard: 0.2803\n",
      "\u001b[32mValid Score Improved (0.0085 ---> 0.0072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 4/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [20:41<00:00,  1.29s/it, gpu_mem=3.25 GB, lr=0.00200, train_loss=0.0074]  \n",
      "Valid : 100%|██████████| 244/244 [01:22<00:00,  2.95it/s, gpu_memory=1.52 GB, lr=0.00200, valid_loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9870 | Valid Jaccard: 0.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 5/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [20:14<00:00,  1.27s/it, gpu_mem=3.25 GB, lr=0.00200, train_loss=0.0072]  \n",
      "Valid : 100%|██████████| 244/244 [01:22<00:00,  2.95it/s, gpu_memory=1.52 GB, lr=0.00200, valid_loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9868 | Valid Jaccard: 0.2980\n",
      "\u001b[32mValid Score Improved (0.0072 ---> 0.0072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 6/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [20:02<00:00,  1.25s/it, gpu_mem=3.25 GB, lr=0.00200, train_loss=0.0068]  \n",
      "Valid : 100%|██████████| 244/244 [01:24<00:00,  2.89it/s, gpu_memory=1.53 GB, lr=0.00200, valid_loss=0.0069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9857 | Valid Jaccard: 0.3014\n",
      "\u001b[32mValid Score Improved (0.0072 ---> 0.0069)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 7/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [19:53<00:00,  1.24s/it, gpu_mem=3.24 GB, lr=0.00200, train_loss=0.0068] \n",
      "Valid : 100%|██████████| 244/244 [01:26<00:00,  2.84it/s, gpu_memory=1.50 GB, lr=0.00200, valid_loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9872 | Valid Jaccard: 0.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 8/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [19:56<00:00,  1.25s/it, gpu_mem=3.25 GB, lr=0.00200, train_loss=0.0065]  \n",
      "Valid : 100%|██████████| 244/244 [01:22<00:00,  2.95it/s, gpu_memory=1.62 GB, lr=0.00200, valid_loss=0.0070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9858 | Valid Jaccard: 0.3233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 9/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [20:23<00:00,  1.28s/it, gpu_mem=3.24 GB, lr=0.00200, train_loss=0.0064]  \n",
      "Valid : 100%|██████████| 244/244 [01:22<00:00,  2.95it/s, gpu_memory=1.50 GB, lr=0.00200, valid_loss=0.0075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9880 | Valid Jaccard: 0.3035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|          | 0/959 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 10/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 959/959 [19:46<00:00,  1.24s/it, gpu_mem=3.25 GB, lr=0.00200, train_loss=0.0063]  \n",
      "Valid : 100%|██████████| 244/244 [02:00<00:00,  2.03it/s, gpu_memory=1.62 GB, lr=0.00200, valid_loss=0.0065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Wandb.\n",
      "Valid Dice: 0.9864 | Valid Jaccard: 0.3255\n",
      "\u001b[32mValid Score Improved (0.0069 ---> 0.0065)\n",
      "\n",
      "\n",
      "Training complete in 3h 37m 50s\n",
      "Best Score: 0.3255\n"
     ]
    }
   ],
   "source": [
    "#for fold in range(5):\n",
    "train_loader, valid_loader = prepare_loaders(df, fold=0, debug=CFG.debug)\n",
    "model = build_model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "model, history = run_training(model, optimizer, scheduler,\n",
    "                              device= CFG.device,\n",
    "                              num_epochs=CFG.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/IoU</td><td>▁▂▅▆▇▇▇▇███</td></tr><tr><td>train/Loss</td><td>██▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val/Dice</td><td>▅▁▅▃▆▅▃▆▄█▅</td></tr><tr><td>val/IoU</td><td>▂▁▄▅▅▆▇▅█▇█</td></tr><tr><td>val/Loss</td><td>▃█▃▂▂▂▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Score IoU</td><td>0.32555</td></tr><tr><td>train/IoU</td><td>0.52548</td></tr><tr><td>train/Loss</td><td>0.0063</td></tr><tr><td>val/Dice</td><td>0.98635</td></tr><tr><td>val/IoU</td><td>0.32555</td></tr><tr><td>val/Loss</td><td>0.00653</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">timm-mobilenetv3_large_100-224x224</strong>: <a href=\"https://wandb.ai/cv-itmo/uw-segmentation/runs/1e6ajxwm\" target=\"_blank\">https://wandb.ai/cv-itmo/uw-segmentation/runs/1e6ajxwm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220629_012624-1e6ajxwm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
