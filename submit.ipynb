{"cells":[{"cell_type":"markdown","metadata":{},"source":["# [UW-Madison GI Tract Image Segmentation](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/)\n","> Track healthy organs in medical scans to improve cancer treatment\n","\n","<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25\">"]},{"cell_type":"markdown","metadata":{},"source":["If we are running notebook in DEBUG status and test data is hidden, then we use train data. But if test data is available (during notebook submition), the notebook uses test data.\n","\n","You should add all necessary data when you are running notebook before submition."]},{"cell_type":"markdown","metadata":{},"source":["## Install Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-06-29T02:46:22.788964Z","iopub.status.busy":"2022-06-29T02:46:22.788301Z","iopub.status.idle":"2022-06-29T02:48:17.907542Z","shell.execute_reply":"2022-06-29T02:48:17.906529Z","shell.execute_reply.started":"2022-06-29T02:46:22.788872Z"},"trusted":true},"outputs":[],"source":["!pip install -q ../input/pytorch-segmentation-models-lib/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\n","!pip install -q ../input/pytorch-segmentation-models-lib/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\n","!pip install -q ../input/pytorch-segmentation-models-lib/timm-0.4.12-py3-none-any.whl\n","!pip install -q ../input/pytorch-segmentation-models-lib/segmentation_models_pytorch-0.2.0-py3-none-any.whl"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries "]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:48:17.910068Z","iopub.status.busy":"2022-06-29T02:48:17.909769Z","iopub.status.idle":"2022-06-29T02:48:26.571120Z","shell.execute_reply":"2022-06-29T02:48:26.570372Z","shell.execute_reply.started":"2022-06-29T02:48:17.910030Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","pd.options.plotting.backend = \"plotly\"\n","import random\n","from glob import glob\n","import os, shutil\n","from tqdm import tqdm\n","tqdm.pandas()\n","import time\n","import copy\n","import joblib\n","from collections import defaultdict\n","import gc\n","from IPython import display as ipd\n","\n","# visualization\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# Sklearn\n","from sklearn.model_selection import StratifiedKFold, KFold\n","\n","# PyTorch \n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda import amp\n","import torch.nn.functional as F\n","\n","import timm\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","c_  = Fore.GREEN\n","sr_ = Style.RESET_ALL\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","import segmentation_models_pytorch"]},{"cell_type":"markdown","metadata":{},"source":["## Configuration "]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:48:26.572744Z","iopub.status.busy":"2022-06-29T02:48:26.572475Z","iopub.status.idle":"2022-06-29T02:48:26.636558Z","shell.execute_reply":"2022-06-29T02:48:26.635618Z","shell.execute_reply.started":"2022-06-29T02:48:26.572709Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    seed          = 101\n","    debug         = False # set debug=False for Full Training\n","    exp_name      = 'Baseline'\n","    comment       = 'unet-efficientnet_b1-224x224'\n","    model_name    = 'Unet'\n","    backbone      = 'efficientnet-b1'\n","    train_bs      = 32\n","    valid_bs      = train_bs\n","    img_size      = [224, 224]\n","    epochs        = 15\n","    lr            = 2e-3\n","    scheduler     = 'CosineAnnealingLR'\n","    min_lr        = 1e-6\n","    T_max         = int(30000/train_bs*epochs)+50\n","    T_0           = 25\n","    warmup_epochs = 0\n","    wd            = 1e-6\n","    n_accumulate  = max(1, 32//train_bs)\n","    n_fold        = 5\n","    num_classes   = 3\n","    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    thr           = 0.45\n","    ttas          = [0]"]},{"cell_type":"markdown","metadata":{},"source":["## Reproducibility"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:48:26.638938Z","iopub.status.busy":"2022-06-29T02:48:26.638656Z","iopub.status.idle":"2022-06-29T02:48:26.655939Z","shell.execute_reply":"2022-06-29T02:48:26.654896Z","shell.execute_reply.started":"2022-06-29T02:48:26.638899Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed = 42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    print('> SEEDING DONE')\n","    \n","set_seed(CFG.seed)"]},{"cell_type":"markdown","metadata":{},"source":["## Utils"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:48:26.658188Z","iopub.status.busy":"2022-06-29T02:48:26.657654Z","iopub.status.idle":"2022-06-29T02:48:26.669422Z","shell.execute_reply":"2022-06-29T02:48:26.667559Z","shell.execute_reply.started":"2022-06-29T02:48:26.658148Z"},"trusted":true},"outputs":[],"source":["def get_metadata(row):\n","    data = row['id'].split('_')\n","    case = int(data[0].replace('case',''))\n","    day = int(data[1].replace('day',''))\n","    slice_ = int(data[-1])\n","    row['case'] = case\n","    row['day'] = day\n","    row['slice'] = slice_\n","    return row\n","\n","def path2info(row):\n","    path = row['image_path']\n","    data = path.split('/')\n","    slice_ = int(data[-1].split('_')[1])\n","    case = int(data[-3].split('_')[0].replace('case',''))\n","    day = int(data[-3].split('_')[1].replace('day',''))\n","    width = int(data[-1].split('_')[2])\n","    height = int(data[-1].split('_')[3])\n","    row['height'] = height\n","    row['width'] = width\n","    row['case'] = case\n","    row['day'] = day\n","    row['slice'] = slice_\n","#     row['id'] = f'case{case}_day{day}_slice_{slice_}'\n","    return row"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:48:26.671557Z","iopub.status.busy":"2022-06-29T02:48:26.670897Z","iopub.status.idle":"2022-06-29T02:48:26.683045Z","shell.execute_reply":"2022-06-29T02:48:26.682299Z","shell.execute_reply.started":"2022-06-29T02:48:26.671516Z"},"trusted":true},"outputs":[],"source":["def load_img(path):\n","    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n","    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n","    img = img.astype('float32') # original is uint16\n","    mx = np.max(img)\n","    if mx:\n","        img/=mx # scale image to [0, 1]\n","    return img\n","\n","def load_msk(path):\n","    msk = np.load(path)\n","    msk = msk.astype('float32')\n","    msk/=255.0\n","    return msk\n","\n","def show_img(img, mask=None):\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","    img = clahe.apply(img)\n","    plt.imshow(img, cmap='bone')\n","    \n","    if mask is not None:\n","        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n","        plt.imshow(mask, alpha=0.5)\n","        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n","        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n","        plt.legend(handles,labels)\n","    plt.axis('off')"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:48:26.686507Z","iopub.status.busy":"2022-06-29T02:48:26.686249Z","iopub.status.idle":"2022-06-29T02:48:26.695719Z","shell.execute_reply":"2022-06-29T02:48:26.694571Z","shell.execute_reply.started":"2022-06-29T02:48:26.686456Z"},"trusted":true},"outputs":[],"source":["# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n","def rle_decode(mask_rle, shape):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (height,width) of array to return \n","    Returns numpy array, 1 - mask, 0 - background\n","\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)  # Needed to align to RLE direction\n","\n","\n","# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n","def rle_encode(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = img.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"cell_type":"markdown","metadata":{},"source":["## Path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T03:00:26.353016Z","iopub.status.busy":"2022-06-29T03:00:26.352763Z","iopub.status.idle":"2022-06-29T03:00:26.359077Z","shell.execute_reply":"2022-06-29T03:00:26.358307Z","shell.execute_reply.started":"2022-06-29T03:00:26.352988Z"},"trusted":true},"outputs":[],"source":["CKPT_DIR = '/kaggle/input/uwgaifullin'"]},{"cell_type":"markdown","metadata":{},"source":["## Test"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T02:50:44.908033Z","iopub.status.busy":"2022-06-29T02:50:44.907477Z","iopub.status.idle":"2022-06-29T02:50:47.013767Z","shell.execute_reply":"2022-06-29T02:50:47.012670Z","shell.execute_reply.started":"2022-06-29T02:50:44.907989Z"},"trusted":true},"outputs":[],"source":["sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n","if not len(sub_df):\n","    debug = True\n","    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n","    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()\n","else:\n","    debug = False\n","    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\n","sub_df = sub_df.progress_apply(get_metadata,axis=1)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T02:50:48.558419Z","iopub.status.busy":"2022-06-29T02:50:48.557606Z","iopub.status.idle":"2022-06-29T02:52:27.772972Z","shell.execute_reply":"2022-06-29T02:52:27.772293Z","shell.execute_reply.started":"2022-06-29T02:50:48.558369Z"},"trusted":true},"outputs":[],"source":["if debug:\n","    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n","else:\n","    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/test/**/*png',recursive=True)\n","path_df = pd.DataFrame(paths, columns=['image_path'])\n","path_df = path_df.progress_apply(path2info, axis=1)\n","path_df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T02:52:27.779030Z","iopub.status.busy":"2022-06-29T02:52:27.777018Z","iopub.status.idle":"2022-06-29T02:52:27.817072Z","shell.execute_reply":"2022-06-29T02:52:27.816250Z","shell.execute_reply.started":"2022-06-29T02:52:27.778987Z"},"trusted":true},"outputs":[],"source":["test_df = sub_df.merge(path_df, on=['case','day','slice'], how='left')\n","test_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Custom Dataset"]},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:52:27.820001Z","iopub.status.busy":"2022-06-29T02:52:27.819593Z","iopub.status.idle":"2022-06-29T02:52:27.841579Z","shell.execute_reply":"2022-06-29T02:52:27.840700Z","shell.execute_reply.started":"2022-06-29T02:52:27.819966Z"},"trusted":true},"outputs":[],"source":["class BuildDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, label=False, transforms=None):\n","        self.df         = df\n","        self.label      = label\n","        self.img_paths  = df['image_path'].tolist()\n","        self.ids        = df['id'].tolist()\n","        if 'msk_path' in df.columns:\n","            self.msk_paths  = df['mask_path'].tolist()\n","        else:\n","            self.msk_paths = None\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        img_path  = self.img_paths[index]\n","        id_       = self.ids[index]\n","        img = []\n","        img = load_img(img_path)\n","        h, w = img.shape[:2]\n","        if self.label:\n","            msk_path = self.msk_paths[index]\n","            msk = load_msk(msk_path)\n","            if self.transforms:\n","                data = self.transforms(image=img, mask=msk)\n","                img  = data['image']\n","                msk  = data['mask']\n","            img = np.transpose(img, (2, 0, 1))\n","            msk = np.transpose(msk, (2, 0, 1))\n","            return torch.tensor(img), torch.tensor(msk)\n","        else:\n","            if self.transforms:\n","                data = self.transforms(image=img)\n","                img  = data['image']\n","            img = np.transpose(img, (2, 0, 1))\n","            return torch.tensor(img), id_, h, w"]},{"cell_type":"markdown","metadata":{},"source":["## Augmentations"]},{"cell_type":"code","execution_count":14,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-06-29T02:52:27.844259Z","iopub.status.busy":"2022-06-29T02:52:27.843745Z","iopub.status.idle":"2022-06-29T02:52:27.858330Z","shell.execute_reply":"2022-06-29T02:52:27.857433Z","shell.execute_reply.started":"2022-06-29T02:52:27.844219Z"},"trusted":true},"outputs":[],"source":["data_transforms = {\n","    \"train\": A.Compose([\n","        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","#         A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=5, p=0.5),\n","        A.OneOf([\n","            A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n","# #             A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n","        ], p=0.25),\n","#         A.CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n","#                          min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n","        ], p=1.0),\n","    \n","    \"valid\": A.Compose([\n","        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n","        ], p=1.0)\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## Model\n"]},{"cell_type":"code","execution_count":15,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:59:26.704009Z","iopub.status.busy":"2022-06-29T02:59:26.703355Z","iopub.status.idle":"2022-06-29T02:59:27.782013Z","shell.execute_reply":"2022-06-29T02:59:27.781302Z","shell.execute_reply.started":"2022-06-29T02:59:26.703973Z"},"trusted":true},"outputs":[],"source":["def build_model():\n","    model = smp.Unet(\n","        encoder_name=CFG.backbone,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n","        encoder_weights=None,     # use `imagenet` pre-trained weights for encoder initialization\n","        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n","        classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n","        activation=None,\n","    )\n","    model.to(CFG.device)\n","    return model\n","\n","def load_model(path):\n","    model = build_model()\n","    model.load_state_dict(torch.load(path))\n","    model.eval()\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## Mask2RLE"]},{"cell_type":"code","execution_count":17,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:59:30.744896Z","iopub.status.busy":"2022-06-29T02:59:30.744408Z","iopub.status.idle":"2022-06-29T02:59:31.967915Z","shell.execute_reply":"2022-06-29T02:59:31.966911Z","shell.execute_reply.started":"2022-06-29T02:59:30.744859Z"},"trusted":true},"outputs":[],"source":["import cupy as cp\n","\n","def mask2rle(msk, thr=0.5):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    msk    = cp.array(msk)\n","    pixels = msk.flatten()\n","    pad    = cp.array([0])\n","    pixels = cp.concatenate([pad, pixels, pad])\n","    runs   = cp.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","def masks2rles(msks, ids, heights, widths):\n","    pred_strings = []; pred_ids = []; pred_classes = [];\n","    for idx in range(msks.shape[0]):\n","        height = heights[idx].item()\n","        width = widths[idx].item()\n","        msk = cv2.resize(msks[idx], \n","                         dsize=(width, height), \n","                         interpolation=cv2.INTER_NEAREST) # back to original shape\n","        rle = [None]*3\n","        for midx in [0, 1, 2]:\n","            rle[midx] = mask2rle(msk[...,midx])\n","        pred_strings.extend(rle)\n","        pred_ids.extend([ids[idx]]*len(rle))\n","        pred_classes.extend(['large_bowel', 'small_bowel', 'stomach'])\n","    return pred_strings, pred_ids, pred_classes"]},{"cell_type":"markdown","metadata":{},"source":["## Inference"]},{"cell_type":"code","execution_count":18,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T02:59:33.458911Z","iopub.status.busy":"2022-06-29T02:59:33.458646Z","iopub.status.idle":"2022-06-29T02:59:33.469835Z","shell.execute_reply":"2022-06-29T02:59:33.469091Z","shell.execute_reply.started":"2022-06-29T02:59:33.458881Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def infer(model_paths, test_loader, num_log=1, thr=CFG.thr):\n","    msks = []; imgs = [];\n","    pred_strings = []; pred_ids = []; pred_classes = [];\n","    for idx, (img, ids, heights, widths) in enumerate(tqdm(test_loader, total=len(test_loader), desc='Infer ')):\n","        img = img.to(CFG.device, dtype=torch.float) # .squeeze(0)\n","        size = img.size()\n","        msk = []\n","        msk = torch.zeros((size[0], 3, size[2], size[3]), device=CFG.device, dtype=torch.float32)\n","        for path in model_paths:\n","            model = load_model(path)\n","            out   = model(img) # .squeeze(0) # removing batch axis\n","            out   = nn.Sigmoid()(out) # removing channel axis\n","            msk+=out/len(model_paths)\n","        msk = (msk.permute((0,2,3,1))>thr).to(torch.uint8).cpu().detach().numpy() # shape: (n, h, w, c)\n","        result = masks2rles(msk, ids, heights, widths)\n","        pred_strings.extend(result[0])\n","        pred_ids.extend(result[1])\n","        pred_classes.extend(result[2])\n","        if idx<num_log:\n","            img = img.permute((0,2,3,1)).cpu().detach().numpy()\n","            imgs.append(img[:10])\n","            msks.append(msk[:10])\n","        del img, msk, out, model, result\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return pred_strings, pred_ids, pred_classes, imgs, msks"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T03:00:52.870001Z","iopub.status.busy":"2022-06-29T03:00:52.869739Z","iopub.status.idle":"2022-06-29T03:01:31.510329Z","shell.execute_reply":"2022-06-29T03:01:31.508534Z","shell.execute_reply.started":"2022-06-29T03:00:52.869974Z"},"trusted":true},"outputs":[],"source":["test_dataset = BuildDataset(test_df, transforms=data_transforms['valid'])\n","test_loader  = DataLoader(test_dataset, batch_size=CFG.valid_bs, \n","                          num_workers=4, shuffle=False, pin_memory=False)\n","model_paths  = glob(f'{CKPT_DIR}/*.pt')\n","pred_strings, pred_ids, pred_classes, imgs, msks = infer(model_paths, test_loader)"]},{"cell_type":"markdown","metadata":{},"source":["## Visualization"]},{"cell_type":"code","execution_count":23,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T03:02:07.224003Z","iopub.status.busy":"2022-06-29T03:02:07.223456Z","iopub.status.idle":"2022-06-29T03:02:09.348888Z","shell.execute_reply":"2022-06-29T03:02:09.348205Z","shell.execute_reply.started":"2022-06-29T03:02:07.223966Z"},"trusted":true},"outputs":[],"source":["for img, msk in zip(imgs[0][5:10], msks[0][5:10]):\n","    plt.figure(figsize=(12, 7))\n","    plt.subplot(1, 3, 1); plt.imshow(img, cmap='bone');\n","    plt.axis('OFF'); plt.title('image')\n","    plt.subplot(1, 3, 2); plt.imshow(msk*255); plt.axis('OFF'); plt.title('mask')\n","    plt.subplot(1, 3, 3); plt.imshow(img, cmap='bone'); plt.imshow(msk*255, alpha=0.4);\n","    plt.axis('OFF'); plt.title('overlay')\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-06-29T03:02:20.490402Z","iopub.status.busy":"2022-06-29T03:02:20.490127Z","iopub.status.idle":"2022-06-29T03:02:20.717177Z","shell.execute_reply":"2022-06-29T03:02:20.716273Z","shell.execute_reply.started":"2022-06-29T03:02:20.490372Z"},"trusted":true},"outputs":[],"source":["del imgs, msks\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## Submission"]},{"cell_type":"code","execution_count":25,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-29T03:02:26.005164Z","iopub.status.busy":"2022-06-29T03:02:26.004640Z","iopub.status.idle":"2022-06-29T03:02:26.313093Z","shell.execute_reply":"2022-06-29T03:02:26.312224Z","shell.execute_reply.started":"2022-06-29T03:02:26.005125Z"},"trusted":true},"outputs":[],"source":["pred_df = pd.DataFrame({\n","    \"id\":pred_ids,\n","    \"class\":pred_classes,\n","    \"predicted\":pred_strings\n","})\n","if not debug:\n","    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n","    del sub_df['predicted']\n","else:\n","    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n","    del sub_df['segmentation']\n","    \n","sub_df = sub_df.merge(pred_df, on=['id','class'])\n","sub_df.to_csv('submission.csv',index=False)\n","display(sub_df.head(5))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"shelf_seg","language":"python","name":"shelf_seg"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
